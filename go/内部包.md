# 内部包

## 1、互斥锁

### 结构

```go
// src/sync/mutex.go
// A Mutex is a mutual exclusion lock.
// The zero value for a Mutex is an unlocked mutex.
//
// A Mutex must not be copied after first use.
//
// In the terminology of the Go memory model,
// the n'th call to Unlock “synchronizes before” the m'th call to Lock
// for any n < m.
// A successful call to TryLock is equivalent to a call to Lock.
// A failed call to TryLock does not establish any “synchronizes before”
// relation at all.
// 互斥锁是一种互斥锁。互斥体的零值是未锁定的互斥体。首次使用后不得复制互斥锁。
// 在 Go 内存模型的术语中，对于任意 n < m，第 n 次 Unlock 调用“同步于”第 m 次 Lock 调用之前。
// 成功调用 TryLock 相当于调用 Lock。对 TryLock 的失败调用根本不会建立任何“同步之前”关系。
type Mutex struct {
    state int32  // 锁当前的状态
    sema  uint32 // 信号量，用于唤醒协程
}
```

### 状态

```go
const (
    mutexLocked      = 1 << iota // mutex is locked 锁是否被占用
    mutexWoken                   // 是否有其他协程被唤醒
    mutexStarving                // 当前锁是否处于饥饿模式，饥饿模式下锁会优先传递给等待时间最长的协程
    mutexWaiterShift = iota      // 记录有多少个协程在等待获取锁

    // Mutex fairness.
    //
    // Mutex can be in 2 modes of operations: normal and starvation.
    // In normal mode waiters are queued in FIFO order, but a woken up waiter
    // does not own the mutex and competes with new arriving goroutines over
    // the ownership. New arriving goroutines have an advantage -- they are
    // already running on CPU and there can be lots of them, so a woken up
    // waiter has good chances of losing. In such case it is queued at front
    // of the wait queue. If a waiter fails to acquire the mutex for more than 1ms,
    // it switches mutex to the starvation mode.
    //
    // In starvation mode ownership of the mutex is directly handed off from
    // the unlocking goroutine to the waiter at the front of the queue.
    // New arriving goroutines don't try to acquire the mutex even if it appears
    // to be unlocked, and don't try to spin. Instead they queue themselves at
    // the tail of the wait queue.
    //
    // If a waiter receives ownership of the mutex and sees that either
    // (1) it is the last waiter in the queue, or (2) it waited for less than 1 ms,
    // it switches mutex back to normal operation mode.
    //
    // Normal mode has considerably better performance as a goroutine can acquire
    // a mutex several times in a row even if there are blocked waiters.
    // Starvation mode is important to prevent pathological cases of tail latency.
    starvationThresholdNs = 1e6 // 饥饿阈值
)
```

互斥锁可能处于两种不同的模式：正常模式和饥饿模式。

在正常模式中，等待者按照FIFO的顺序排队获取锁，但是一个被唤醒的等待者有时候并不能获取mutex，它还需要和新到来的协程竞争mutex的使用权。新到来的协程存在一个优势，它们已经在CPU上运行且数量很多，因此一个被唤醒的等待者有很大的概率获取不到锁，在这种情况下它处在等待队列的前面。如果一个协程等待mutex释放的时间超过1ms，它就会将mutex切换到饥饿模式。

在饥饿模式中，mutex的所有权直接从解锁的协程递交到等待队列中排在最前方的协程。新到达的协程不要尝试获取mutex，即使它看起来是在解锁状态，也不要试图自旋，而是排到等待队列的尾部。

如果一个等待者获得mutex的所有权，并且看到以下两种情况中的任意一种：

1）它是等待队列中的最后一个。

2）它等待的时间少于1ms，它便将mutex切换回正常操作模式

正常模式下的性能会更好，因为一个协程能在即使有很多阻塞的等待者时多次连续的获得一个mutex，<span style='color:red'>饥饿模式的重要性在于避免了病态情况下的尾部延迟。</span>

### 加锁

Lock对申请锁的情况分为三种：

1. 无冲突，通过CAS操作把当前状态设置为加锁状态
2. 有冲突，开始自旋，并等待锁释放，如果其他协程在这段时间内释放该锁，直接获得该锁；没有释放则为下一种情况。
3. 有冲突，且已经过了自旋阶段，通过调用semrelease让协程进入等待状态。

```go
// Lock locks m.
// If the lock is already in use, the calling goroutine
// blocks until the mutex is available.
func (m *Mutex) Lock() {
    // Fast path: grab unlocked mutex.
    if atomic.CompareAndSwapInt32(&m.state, 0, mutexLocked) {
        // 锁在调用时未被占用，则设置为锁定状态
        if race.Enabled {
            // 启用竟态检测，记录锁的恶获取
            race.Acquire(unsafe.Pointer(m))
        }
        return
    }
    // Slow path (outlined so that the fast path can be inlined)
    // 锁已被其他协程持有则进入慢速路径进行处理
    m.lockSlow()
}

func (m *Mutex) lockSlow() {
    var waitStartTime int64 // 记录开始等待的时间
    starving := false       // 表示当前是否处于饥饿模式
    awoke := false          // 表示当前协程是否已被唤醒
    iter := 0               // 用于记录自旋次数
    old := m.state          // 保存锁的当前状态
    for {
        // Don't spin in starvation mode, ownership is handed off to waiters
        // so we won't be able to acquire the mutex anyway.
        // 锁已被占用但尚未处于饥饿状态并且满足自旋条件
        if old&(mutexLocked|mutexStarving) == mutexLocked && runtime_canSpin(iter) {
            // 通过自旋的方式获取锁而不是立即进入阻塞状态
            // Active spinning makes sense.
            // Try to set mutexWoken flag to inform Unlock
            // to not wake other blocked goroutines.
            // mutexWoken未设置并且有等待的协程，则尝试设置mutexWoken，告知后续的解锁操作不要唤醒其他协程
            if !awoke && old&mutexWoken == 0 && old>>mutexWaiterShift != 0 &&
                atomic.CompareAndSwapInt32(&m.state, old, old|mutexWoken) {
                awoke = true
            }
            runtime_doSpin()
            iter++
            old = m.state
            continue
        }
        new := old
        // Don't try to acquire starving mutex, new arriving goroutines must queue.
        // 不要尝试获取一个饥饿的锁，新到来的协程必须在队列中
        if old&mutexStarving == 0 {
            // 锁未处于饥饿状态，当前协程不是在被唤醒后重新尝试获取锁，则将状态更新为已锁住
            new |= mutexLocked
        }
        if old&(mutexLocked|mutexStarving) != 0 {
            // 当前锁已被锁定或正处于饥饿模式，则增加等待协程计数，表示有更多的协程在等待
            new += 1 << mutexWaiterShift
        }
        // The current goroutine switches mutex to starvation mode.
        // But if the mutex is currently unlocked, don't do the switch.
        // Unlock expects that starving mutex has waiters, which will not
        // be true in this case.
        // 饥饿模式处理
        // 当锁进入饥饿模式后，新来的协程将不再尝试自旋获取锁，直接排队等待
        if starving && old&mutexLocked != 0 {
            new |= mutexStarving
        }
        if awoke {
            // The goroutine has been woken from sleep,
            // so we need to reset the flag in either case.
            if new&mutexWoken == 0 {
                throw("sync: inconsistent mutex state")
            }
            new &^= mutexWoken
        }
        if atomic.CompareAndSwapInt32(&m.state, old, new) {
            // 锁获取成功
            if old&(mutexLocked|mutexStarving) == 0 {
                break // locked the mutex with CAS
            }
            // If we were already waiting before, queue at the front of the queue.
            // 当前协程之前就在等待锁了，应该排在等待队列前面
            queueLifo := waitStartTime != 0
            if waitStartTime == 0 {
                // 第一次进入等待状态，则将当前的纳秒时间戳记录，表示从这一刻开始记录等待时间
                waitStartTime = runtime_nanotime()
            }
            // 阻塞等待
            runtime_SemacquireMutex(&m.sema, queueLifo, 1)
            // 检查协程是否进入了饥饿模式，阻塞时间大于1ms或者正处于饥饿模式
            starving = starving || runtime_nanotime()-waitStartTime > starvationThresholdNs
            old = m.state
            if old&mutexStarving != 0 {
                // If this goroutine was woken and mutex is in starvation mode,
                // ownership was handed off to us but mutex is in somewhat
                // inconsistent state: mutexLocked is not set and we are still
                // accounted as waiter. Fix that.
                // 修正锁的状态：如果当前协程被唤醒并处于饥饿模式，那么锁的所有权会被直接交给当前协程。
                // 但此时锁的状态可能不一致，特别是锁的mutexLocked标志位可能没有被重置。
                // 虽然当前协程已经获取了锁，因此需要修正
                // 如果这两个标志位仍然被重置，或者等待计数为0，会触发异常，表示锁的状态不一致
                if old&(mutexLocked|mutexWoken) != 0 || old>>mutexWaiterShift == 0 {
                    throw("sync: inconsistent mutex state")
                }
                // 修正锁的状态
                // 设置锁定标志位并减少一个等待者引用计数
                delta := int32(mutexLocked - 1<<mutexWaiterShift)
                if !starving || old>>mutexWaiterShift == 1 {
                    // 当前协程没有进入饥饿模式，或者这是最后一个等待者，则解除饥饿模式
                    // Exit starvation mode.
                    // Critical to do it here and consider wait time.
                    // Starvation mode is so inefficient, that two goroutines
                    // can go lock-step infinitely once they switch mutex
                    // to starvation mode.
                    delta -= mutexStarving
                }
                // 修正
                atomic.AddInt32(&m.state, delta)
                break
            }
            awoke = true
            iter = 0
        } else {
            old = m.state
        }
    }

    if race.Enabled {
        race.Acquire(unsafe.Pointer(m))
    }
}
```

### 解锁

```go

// Unlock unlocks m.
// It is a run-time error if m is not locked on entry to Unlock.
//
// A locked Mutex is not associated with a particular goroutine.
// It is allowed for one goroutine to lock a Mutex and then
// arrange for another goroutine to unlock it.
func (m *Mutex) Unlock() {
    if race.Enabled {
        _ = m.state
        race.Release(unsafe.Pointer(m))
    }

    // Fast path: drop lock bit.
    // 清除标记，解锁
    new := atomic.AddInt32(&m.state, -mutexLocked)
    if new != 0 {
        // Outlined slow path to allow inlining the fast path.
        // To hide unlockSlow during tracing we skip one extra frame when tracing GoUnblock.
        // 其他协程在等待此锁或其他状态位被设置，因此进入慢速路径处理
        m.unlockSlow(new)
    }
}

func (m *Mutex) unlockSlow(new int32) {
    // 重复解锁判定
    if (new+mutexLocked)&mutexLocked == 0 {
        fatal("sync: unlock of unlocked mutex")
    }
    if new&mutexStarving == 0 {
        // 非饥饿模式
        old := new
        for {
            // If there are no waiters or a goroutine has already
            // been woken or grabbed the lock, no need to wake anyone.
            // In starvation mode ownership is directly handed off from unlocking
            // goroutine to the next waiter. We are not part of this chain,
            // since we did not observe mutexStarving when we unlocked the mutex above.
            // So get off the way.
            if old>>mutexWaiterShift == 0 || old&(mutexLocked|mutexWoken|mutexStarving) != 0 {
                // 没有等待者，锁已经被其他协程获取或者处于饥饿模式，直接返回
                return
            }
            // Grab the right to wake someone.
            // 尝试更新状态
            new = (old - 1<<mutexWaiterShift) | mutexWoken
            if atomic.CompareAndSwapInt32(&m.state, old, new) {
                // 唤醒一个阻塞的协程，而不是唤醒一个等待者
                runtime_Semrelease(&m.sema, false, 1)
                return
            }
            old = m.state
        }
    } else {
        // Starving mode: handoff mutex ownership to the next waiter, and yield
        // our time slice so that the next waiter can start to run immediately.
        // Note: mutexLocked is not set, the waiter will set it after wakeup.
        // But mutex is still considered locked if mutexStarving is set,
        // so new coming goroutines won't acquire it.
        // 饥饿模式下，锁的所有权会直接交给下一个等待者，而不是由刚释放锁的协程继续占有锁
        // 唤醒下一个等待者，也就是等待队列最前端的协程
        runtime_Semrelease(&m.sema, true, 1)
    }
}
```

### 并发安全的单例模式

利用原子操作和互斥锁，可以轻松实现一个非常简单的并发安全的单例模式

```go
// Once is an object that will perform exactly one action.
//
// A Once must not be copied after first use.
//
// In the terminology of the Go memory model,
// the return from f “synchronizes before”
// the return from any call of once.Do(f).
type Once struct {
    // done indicates whether the action has been performed.
    // It is first in the struct because it is used in the hot path.
    // The hot path is inlined at every call site.
    // Placing done first allows more compact instructions on some architectures (amd64/386),
    // and fewer instructions (to calculate offset) on other architectures.
    // done表示某个动作是否被执行，done放在第一位，在某些架构下可以获得更加紧凑的指令
    done uint32
    m    Mutex
}

// Do calls the function f if and only if Do is being called for the
// first time for this instance of Once. In other words, given
//
//	var once Once
//
// if once.Do(f) is called multiple times, only the first call will invoke f,
// even if f has a different value in each invocation. A new instance of
// Once is required for each function to execute.
//
// Do is intended for initialization that must be run exactly once. Since f
// is niladic, it may be necessary to use a function literal to capture the
// arguments to a function to be invoked by Do:
//
//	config.once.Do(func() { config.init(filename) })
//
// Because no call to Do returns until the one call to f returns, if f causes
// Do to be called, it will deadlock.
//
// If f panics, Do considers it to have returned; future calls of Do return
// without calling f.
// Do当且仅当第一次调用时，f会被执行
// f如果调用了Do会导致死锁
// 即使f发生了panic，也不会再次调用
func (o *Once) Do(f func()) {
    // Note: Here is an incorrect implementation of Do:
    //
    //	if atomic.CompareAndSwapUint32(&o.done, 0, 1) {
    //		f()
    //	}
    //
    // Do guarantees that when it returns, f has finished.
    // This implementation would not implement that guarantee:
    // given two simultaneous calls, the winner of the cas would
    // call f, and the second would return immediately, without
    // waiting for the first's call to f to complete.
    // This is why the slow path falls back to a mutex, and why
    // the atomic.StoreUint32 must be delayed until after f returns.
    // 原子读取Once内部的done属性，为0则进入慢速路径，否则直接调用
    if atomic.LoadUint32(&o.done) == 0 {
        // Outlined slow-path to allow inlining of the fast-path.
        o.doSlow(f)
    }
}

func (o *Once) doSlow(f func()) {
    // 必须加锁，有可能有很多个协程读到0
    o.m.Lock()
    defer o.m.Unlock()
    // 一个协程拿到锁
    if o.done == 0 {
        // 如果是0，代表没执行过，执行f，并更新done值
        defer atomic.StoreUint32(&o.done, 1)
        f()
    }
}
```

## 2、原子操作

atomic包中包含了很多原子型操作。它们均基于运行`runtime/internal/atomic` 的实现。

原子操作依赖硬件指令的支持，但同时还需要运行时调度器的配合。

```go
func CompareAndSwapPointer(addr *unsafe.Pointer, old, new unsafe.Pointer) (swapped bool)
```

函数仅有定义，其本身由运行时实现。

```go
//go:linkname sync_atomic_CompareAndSwapUintptr sync/atomic.CompareAndSwapUintptr
func sync_atomic_CompareAndSwapUintptr(ptr *uintptr, old, new uintptr) bool

//go:linkname sync_atomic_CompareAndSwapPointer sync/atomic.CompareAndSwapPointer
//go:nosplit
func sync_atomic_CompareAndSwapPointer(ptr *unsafe.Pointer, old, new unsafe.Pointer) bool {
	if writeBarrier.enabled {
		atomicwb(ptr, new)
	}
	return sync_atomic_CompareAndSwapUintptr((*uintptr)(noescape(unsafe.Pointer(ptr))), uintptr(old), uintptr(new))
}
```

```text
// bool	·Cas64(uint64 *val, uint64 old, uint64 new)
// Atomically:
//	if(*val == old){
//		*val = new;
//		return 1;
//	} else {
//		return 0;
//	}
TEXT ·Cas64(SB), NOSPLIT, $0-25
	MOVQ	ptr+0(FP), BX
	MOVQ	old+8(FP), AX
	MOVQ	new+16(FP), CX
	LOCK
	CMPXCHGQ	CX, 0(BX)
	SETEQ	ret+24(FP)
	RET
```

实现的本质是使用CPU的LOCK和CMPXCHGQ指令。<span style='color:red'>原子操作本质上均为使用CPU指令进行实现。</span>

原子值需要运行时的支持，在原子值进行修改时，协程不应该被抢占，因此需要锁定MP之间的绑定关系

```go
// src/runtime/proc.go
//go:nosplit
func procPin() int {
    gp := getg()
    mp := gp.m

    mp.locks++
    return int(mp.p.ptr().id)
}

//go:nosplit
func procUnpin() {
    gp := getg()
    gp.m.locks--
}

//go:linkname sync_runtime_procPin sync.runtime_procPin
//go:nosplit
func sync_runtime_procPin() int {
    return procPin()
}

//go:linkname sync_runtime_procUnpin sync.runtime_procUnpin
//go:nosplit
func sync_runtime_procUnpin() {
    procUnpin()
}

//go:linkname sync_atomic_runtime_procPin sync/atomic.runtime_procPin
//go:nosplit
func sync_atomic_runtime_procPin() int {
    return procPin()
}

//go:linkname sync_atomic_runtime_procUnpin sync/atomic.runtime_procUnpin
//go:nosplit
func sync_atomic_runtime_procUnpin() {
    procUnpin()
}
```

原子值atomic.Value提供了一种具备原子存取的结构。

```go
// src/sync/atomic/value.go
// A Value provides an atomic load and store of a consistently typed value.
// The zero value for a Value returns nil from Load.
// Once Store has been called, a Value must not be copied.
//
// A Value must not be copied after first use.
type Value struct {
    v any
}
```

读取方法：这个Load方法实际上使用了Go运行时类型系统interface{}这一类型本质上由两段内容组成，一个是类型typ区域，另一个是实际数据data区域。Load方法的实现本质上就是将内部存储的类型和数据都复制一份并返回。

```go
// interface{}类型的内部表示
// efaceWords is interface{} internal representation.
type efaceWords struct {
    typ  unsafe.Pointer // 类型部分
    data unsafe.Pointer // 数值部分
}

// Load returns the value set by the most recent Store.
// It returns nil if there has been no call to Store for this Value.
func (v *Value) Load() (val any) {
    // 获得interface结构指针
    vp := (*efaceWords)(unsafe.Pointer(v))
    // 获得存储值的类型指针
    typ := LoadPointer(&vp.typ)
    if typ == nil || typ == unsafe.Pointer(&firstStoreInProgress) {
        // First store not yet completed.
        return nil
    }
    // 获得存储值的数据指针
    data := LoadPointer(&vp.data)
    // 复制一个对象赋值并返回
    vlp := (*efaceWords)(unsafe.Pointer(&val))
    vlp.typ = typ
    vlp.data = data
    return
}
```

存储方法：由于类型系统的两段式表示（typ和data）的存在，存储操作比读取操作的实现要更加小心，要考虑当两个不同的协程对两段值进行写入时，需要避免写竞争。

```go
var firstStoreInProgress byte

// Store sets the value of the Value v to val.
// All calls to Store for a given Value must use values of the same concrete type.
// Store of an inconsistent type panics, as does Store(nil).
func (v *Value) Store(val any) {
    if val == nil {
        panic("sync/atomic: store of nil value into Value")
    }
    vp := (*efaceWords)(unsafe.Pointer(v))
    vlp := (*efaceWords)(unsafe.Pointer(&val))
    for {
        typ := LoadPointer(&vp.typ)
        if typ == nil {
            // 第一次存储数据，要保证第一次存储顺利完成
            // Attempt to start first store.
            // Disable preemption so that other goroutines can use
            // active spin wait to wait for completion.
            // 禁止抢占当前协程来确保存储顺利完成
            runtime_procPin()
            if !CompareAndSwapPointer(&vp.typ, nil, unsafe.Pointer(&firstStoreInProgress)) {
                // 如果没有成功，取消不可抢占，下次再试
                runtime_procUnpin()
                continue
            }
            // Complete first store.
            // 标志位设置成功，则其他协程不会写入，放心存储
            StorePointer(&vp.data, vlp.data)
            StorePointer(&vp.typ, vlp.typ)
            // 取消不可抢占，返回
            runtime_procUnpin()
            return
        }

        // 等待初次存储完成
        if typ == unsafe.Pointer(&firstStoreInProgress) {
            // First store in progress. Wait.
            // Since we disable preemption around the first store,
            // we can wait with active spinning.
            continue
        }
        // First store completed. Check type and overwrite data.
        // 检查类型是否一致
        if typ != vlp.typ {
            panic("sync/atomic: store of inconsistently typed value into Value")
        }
        // 类型已经写入，直接保存数据
        // 不是第一次存储，只需要原子更新值即可
        StorePointer(&vp.data, vlp.data)
        return
    }
}
```

只有在第一次存储时，禁止其他协程抢占，以确保类型赋值这个关键操作能顺利完成。在第一次存储时，sync/atomic.Value需要初始化类型信息，并将数据指针与类型指针一起原子性地存储到Value中。

第一次存储时禁止抢占的目的是为了避免在存储过程中被其他协程打断，确保typ和data的存储操作能够连续完成。如果在第一次存储时被抢占，可能会导致其他协程在读取或存储数据时遇到不一致的状态。

在第一次存储之后，Value的typ字段已经设置完成，此时再进行存储时不再需要禁止抢占，因为后续的存储操作只需要检查类型一致性并更新数据即可，不涉及初始化操作。后续存储的类型检查和数据更新操作都是原子性的，可以在协程被抢占的情况下安全进行。

## 3、条件变量

一种同步原语，用于协程（或线程）之间的协调与通信。它允许一个或多个协程等待某个条件满足，并在 条件满足时被唤醒，继续执行后续操作。<span style='color:red'>条件变量通常与互斥锁一起使用，以确保对共享资源的安全访问。</span>

<span style='color:red'>在共享资源不满足某些条件时，将协程挂起，从而避免忙等，并在条件满足时通过通知机制唤醒等待的协程。</span>

使用条件变量的步骤：

1. 获取锁：在操作共享资源之前，通常需要先获取互斥锁。
2. 检查条件：检查共享资源是否满足某个条件。如果条件不满足，则调用条件变量的等待方法，将当前协程挂起，并释放互斥锁。
3. 等待条件：在等待过程中，当前协程会被挂起，不占用CPU资源。此时，其他协程可以获取互斥锁并修改共享资源。
4. 条件满足被唤醒：当条件满足时，某个协程会通过条件变量的通知方法唤醒等待的协程。
5. 重新获取锁：被唤醒的协程会重新获取互斥锁，并继续执行后续操作。
6. 释放锁：操作完成后，释放互斥锁。

条件变量结构：

内部结构包含一个锁，通知列表以及一个复制检查器，<span style='color:red'>条件变量结构不允许被复制。</span>

```go
// src/sync/conf.go
// Cond implements a condition variable, a rendezvous point
// for goroutines waiting for or announcing the occurrence
// of an event.
//
// Each Cond has an associated Locker L (often a *Mutex or *RWMutex),
// which must be held when changing the condition and
// when calling the Wait method.
//
// A Cond must not be copied after first use.
//
// In the terminology of the Go memory model, Cond arranges that
// a call to Broadcast or Signal “synchronizes before” any Wait call
// that it unblocks.
//
// For many simple use cases, users will be better off using channels than a
// Cond (Broadcast corresponds to closing a channel, and Signal corresponds to
// sending on a channel).
//
// For more on replacements for sync.Cond, see [Roberto Clapis's series on
// advanced concurrency patterns], as well as [Bryan Mills's talk on concurrency
// patterns].
//
// [Roberto Clapis's series on advanced concurrency patterns]: https://blogtitle.github.io/categories/concurrency/
// [Bryan Mills's talk on concurrency patterns]: https://drive.google.com/file/d/1nPdvhB0PutEJzdCq5ms6UI58dp50fcAN/view
type Cond struct {
	noCopy noCopy

	// L is held while observing or changing the condition
	L Locker

	notify  notifyList
	checker copyChecker
}

// NewCond returns a new Cond with Locker l.
func NewCond(l Locker) *Cond {
	return &Cond{L: l}
}
```

复制检查器：

```go
// copyChecker holds back pointer to itself to detect object copying.
type copyChecker uintptr

func (c *copyChecker) check() {
    // 比较存储在copyChecker中的地址和本身的内存地址，如果不同那么可能被复制了
    // 如果不同，则尝试设置为当前对象的地址。
    // 然后再次进行比较
    if uintptr(*c) != uintptr(unsafe.Pointer(c)) &&
        !atomic.CompareAndSwapUintptr((*uintptr)(c), 0, uintptr(unsafe.Pointer(c))) &&
        uintptr(*c) != uintptr(unsafe.Pointer(c)) {
        panic("sync.Cond is copied")
    }
}
```

Wait/Signal/Broadcast

Wait方法向notifyList注册一个通知，然后阻塞到被通知，Signal则负责通知一个在notifyList注册过的等待者协程发出通知，Broadcast直接粗暴的向所有等待者都发出通知。

细节：

Wait：

1、Wait原子式的解锁，并暂停执行调用的协程。它会自动地、原子地解锁与条件变量关联的互斥锁，然后会将调用Wait的协程置于阻塞状态，等待其他协程通过Signal或Broadcast唤醒它。

<span style='color:red'>解锁操作是原子性的，意味着在协程被阻塞之前，锁会被释放，从而允许其他协程进入临界区操作。</span>

2、在稍后执行后，Wait会在返回前加锁。当Wait被Signal或Broadcast唤醒时，Wait方法会在返回之前重新锁定与条件变量关联的互斥锁。

<span style='color:red'>Wait返回时，调用它的协程已经重新获取了互斥锁，确保调用者可以安全地检查并操作共享资源。</span>

3、与其他系统不同，除非被Broadcast或Signal唤醒，否则等待无法返回。

<span style='color:red'>POSIX线程库中的条件变量实现可能存在虚假唤醒（即Wait没有明确唤醒就返回），</span>Go中的条件变量的实现保证只有在接收到Signal或Broadcast后，Wait才会返回。

4、因为等待第一次恢复时没有处于锁定状态，所以当Wait返回时，调用者通常不能认为条件为真。

当Wait返回时，不能直接假设等待的条件已经满足了，虽然Wait调用后会重新获得互斥锁，但在Wait返回之前，其他协程可能已经改变了共享资源的状态。因此，条件可能不再为真。

<span style='color:red'>Wait返回时，虽然互斥锁已被重新获取，但仍需再次检查条件是否满足。</span>

5、调用者应该在循环中使用Wait

对使用条件变量的最佳实践的建议。由于条件变量在被唤醒时，条件可能并不一定为真，因此调用Wait的正确方式是将它放在循环中，并在每次唤醒时重新检查条件是否满足。

Signal：

1、Signal方法会唤醒一个正在sync.Cond上等待的协程。这个唤醒的协程是之前调用了Wait方法并被阻塞的某个协程。

<span style='color:red'>Signal只会唤醒一个等待的协程，而不是所有等待的协程。如果有多个协程在等待，只有其中一个会被唤醒。</span>

2、调用Signal方法，调用者可以持有sync.Cond关联的互斥锁，但这不是必须的。

<span style='color:red'>在某些情况下，持有互斥锁来调用Signal可以确保调用Signal的线程与被唤醒的线程之间的顺序和数据一致性。但Go语言的设计允许你在不持有锁的情况下调用Signal，这提供了更大的灵活性。</span>

3、调用Signal并不会改变协程的调度优先级。如果有其他协程正在尝试获取互斥锁，这些协程可能会在唤醒的等待协程之前被调度执行。

Signal只负责唤醒一个等待的协程，但在竞争锁时，调度器不会优先让这个被唤醒的协程获得锁。这意味着被唤醒的协程可能并不会立即执行，其他尝试锁定的协程可能会先执行。

<span style='color:red'>Signal调用本身并不会自动解锁关联的互斥锁。在使用条件变量的时候，通常的做法是先锁定互斥锁，然后在某些条件下调用Wait方法。Wait方法会在调用时自动解锁，被唤醒后再重新锁定。但Signal方法只负责唤醒一个等待中的协程，并不会解锁或锁定。</span>

如果在调用Signal之前持有了锁，锁仍然会被持有，直到显式调用解锁。

Broadcast和Signal原理差不多。

```go
// Wait atomically unlocks c.L and suspends execution
// of the calling goroutine. After later resuming execution,
// Wait locks c.L before returning. Unlike in other systems,
// Wait cannot return unless awoken by Broadcast or Signal.
//
// Because c.L is not locked while Wait is waiting, the caller
// typically cannot assume that the condition is true when
// Wait returns. Instead, the caller should Wait in a loop:
//
//	c.L.Lock()
//	for !condition() {
//	    c.Wait()
//	}
//	... make use of condition ...
//	c.L.Unlock()
// Wait 原子式的 unlock c.L， 并暂停执行调用的 goroutine。
// 在稍后执行后，Wait 会在返回前 lock c.L. 与其他系统不同，
// 除非被 Broadcast 或 Signal 唤醒，否则等待无法返回。
//
// 因为等待第一次 resume 时 c.L 没有被锁定，所以当 Wait 返回时，
// 调用者通常不能认为条件为真。相反，调用者应该在循环中使用 Wait()：
//
//    c.L.Lock()
//    for !condition() {
//        c.Wait()
//    }
//    ... make use of condition ...
//    c.L.Unlock()
//
func (c *Cond) Wait() {
    c.checker.check()
    t := runtime_notifyListAdd(&c.notify)
    c.L.Unlock()
    runtime_notifyListWait(&c.notify, t)
    c.L.Lock()
}

// Signal wakes one goroutine waiting on c, if there is any.
//
// It is allowed but not required for the caller to hold c.L
// during the call.
//
// Signal() does not affect goroutine scheduling priority; if other goroutines
// are attempting to lock c.L, they may be awoken before a "waiting" goroutine.
// Signal 唤醒一个等待 c 的 goroutine（如果存在）
//
// 在调用时它可以（不必须）持有一个 c.L
func (c *Cond) Signal() {
    c.checker.check()
    runtime_notifyListNotifyOne(&c.notify)
}

// Broadcast wakes all goroutines waiting on c.
//
// It is allowed but not required for the caller to hold c.L
// during the call.
// Broadcast 唤醒等待 c 的所有 goroutine
//
// 调用时它可以（不必须）持久有个 c.L
func (c *Cond) Broadcast() {
    c.checker.check()
    runtime_notifyListNotifyAll(&c.notify)
}
```

notifyList

条件变量的实现核心本质上是一个通知列表，也就是一个队列。

当一个Cond调用Wait方法时，向Wait字段加一，并返回一个ticket编号，然后使用这个ticket编号来等待通知，这个过程会将等待通知的协程进行停泊，进入等待状态，并将其M与P解绑，从而将G从M身上剥离，放入等待队列sudog中。当Signal调用时，会有一个在等待的协程被通知到，具体过程就是从sudog列表中找到要通知的协程，然后将其goready来等待调度循环将其调度。

```go
// src/runtime/sema.go
// notifyList is a ticket-based notification list used to implement sync.Cond.
//
// It must be kept in sync with the sync package.
type notifyList struct {
    // wait is the ticket number of the next waiter. It is atomically
    // incremented outside the lock.
    // wait 为下一个 waiter 的 ticket 编号
    // 在没有 lock 的情况下原子自增
    wait atomic.Uint32

    // notify is the ticket number of the next waiter to be notified. It can
    // be read outside the lock, but is only written to with lock held.
    //
    // Both wait & notify can wrap around, and such cases will be correctly
    // handled as long as their "unwrapped" difference is bounded by 2^31.
    // For this not to be the case, we'd need to have 2^31+ goroutines
    // blocked on the same condvar, which is currently not possible.
    //
    // notify 是下一个被通知的 waiter 的 ticket 编号
    // 它可以在没有 lock 的情况下进行读取，但只有在持有 lock 的情况下才能进行写
    //
    // wait 和 notify 会产生 wrap around，只要它们 "unwrapped"
    // 的差别小于 2^31，这种情况可以被正确处理。对于 wrap around 的情况而言，
    // 我们需要超过 2^31+ 个 goroutine 阻塞在相同的 condvar 上，这是不可能的。
    //
    notify uint32

    // List of parked waiters.
    // waiter 列表.
    lock mutex
    head *sudog
    tail *sudog
}

// less checks if a < b, considering a & b running counts that may overflow the
// 32-bit range, and that their "unwrapped" difference is always less than 2^31.
func less(a, b uint32) bool {
    return int32(a-b) < 0
}

// notifyListAdd adds the caller to a notify list such that it can receive
// notifications. The caller must eventually call notifyListWait to wait for
// such a notification, passing the returned ticket number.
//
// notifyListAdd 将调用者添加到通知列表，以便接收通知。
// 调用者最终必须调用 notifyListWait 等待这样的通知，并传递返回的 ticket 编号。
//go:linkname notifyListAdd sync.runtime_notifyListAdd
func notifyListAdd(l *notifyList) uint32 {
    // This may be called concurrently, for example, when called from
    // sync.Cond.Wait while holding a RWMutex in read mode.
    // 这可以并发调用，例如，当在 read 模式下保持 RWMutex 时从 sync.Cond.Wait 调用时。
    return l.wait.Add(1) - 1
}

// notifyListWait waits for a notification. If one has been sent since
// notifyListAdd was called, it returns immediately. Otherwise, it blocks.
//
// notifyListWait 等待通知。如果在调用 notifyListAdd 后发送了一个，则立即返回。否则，它会阻塞。
//go:linkname notifyListWait sync.runtime_notifyListWait
func notifyListWait(l *notifyList, t uint32) {
    // 锁定通知列表，确保并发安全性
    lockWithRank(&l.lock, lockRankNotifyList)

    // Return right away if this ticket has already been notified.
    // 如果 ticket 编号对应的 goroutine 已经被通知到，则立刻返回
    if less(t, l.notify) {
        unlock(&l.lock)
        return
    }

    // Enqueue itself.
    // 将当前协程加入等待队列
    s := acquireSudog()
    s.g = getg()
    s.ticket = t
    s.releasetime = 0
    t0 := int64(0)
    if blockprofilerate > 0 {
        t0 = cputicks()
        s.releasetime = -1
    }
    // 更新等待队列
    if l.tail == nil {
        l.head = s
    } else {
        l.tail.next = s
    }
    l.tail = s
    // 挂起协程并释放锁，等待被唤醒
    goparkunlock(&l.lock, waitReasonSyncCondWait, traceEvGoBlockCond, 3)
    // 唤醒后释放sudog
    if t0 != 0 {
        blockevent(s.releasetime-t0, 2)
    }
    releaseSudog(s)
}

// notifyListNotifyAll notifies all entries in the list.
//
//go:linkname notifyListNotifyAll sync.runtime_notifyListNotifyAll
func notifyListNotifyAll(l *notifyList) {
    // Fast-path: if there are no new waiters since the last notification
    // we don't need to acquire the lock.
    if l.wait.Load() == atomic.Load(&l.notify) {
        return
    }

    // Pull the list out into a local variable, waiters will be readied
    // outside the lock.
    lockWithRank(&l.lock, lockRankNotifyList)
    s := l.head
    l.head = nil
    l.tail = nil

    // Update the next ticket to be notified. We can set it to the current
    // value of wait because any previous waiters are already in the list
    // or will notice that they have already been notified when trying to
    // add themselves to the list.
    atomic.Store(&l.notify, l.wait.Load())
    unlock(&l.lock)

    // Go through the local list and ready all waiters.
    for s != nil {
        next := s.next
        s.next = nil
        readyWithTime(s, 4)
        s = next
    }
}

// notifyListNotifyOne notifies one entry in the list.
//
// 通知列表中的一个条目
//go:linkname notifyListNotifyOne sync.runtime_notifyListNotifyOne
func notifyListNotifyOne(l *notifyList) {
    // Fast-path: if there are no new waiters since the last notification
    // we don't need to acquire the lock at all.
    // 快速路径检查：函数检查自上次通知以来是否有新的等待者，如果wait和notify的值相等
    // 表示没有等待者，无需继续执行操作
    if l.wait.Load() == atomic.Load(&l.notify) {
        return
    }

    lockWithRank(&l.lock, lockRankNotifyList)

    // Re-check under the lock if we need to do anything.
    // 锁内重排检查，在获取锁后，二次检查两者的值，如果相等则还是没有需要通知的等待者
    t := l.notify
    if t == l.wait.Load() {
        unlock(&l.lock)
        return
    }

    // Update the next notify ticket number.
    // 更新通知序号
    atomic.Store(&l.notify, t+1)

    // Try to find the g that needs to be notified.
    // If it hasn't made it to the list yet we won't find it,
    // but it won't park itself once it sees the new notify number.
    //
    // This scan looks linear but essentially always stops quickly.
    // Because g's queue separately from taking numbers,
    // there may be minor reorderings in the list, but we
    // expect the g we're looking for to be near the front.
    // The g has others in front of it on the list only to the
    // extent that it lost the race, so the iteration will not
    // be too long. This applies even when the g is missing:
    // it hasn't yet gotten to sleep and has lost the race to
    // the (few) other g's that we find on the list.
    // 尝试找到需要通知的sudog
    for p, s := (*sudog)(nil), l.head; s != nil; p, s = s, s.next {
        if s.ticket == t {
            // 在列表中移除
            n := s.next
            if p != nil {
                p.next = n
            } else {
                l.head = n
            }
            if n == nil {
                l.tail = p
            }
            unlock(&l.lock)
            s.next = nil
            readyWithTime(s, 4)
            return
        }
    }
    unlock(&l.lock)
}
```

## 4、同步组

sync.WaitGroup 可以达到并发 Goroutine 的执行屏障的效果，等待多个 Goroutine 执行完毕。

WaitGroup的内部结构：

<span style='color:red'>WaitGroup 在第一次使用后不能被复制.</span>

```go
// src/sync/waitgroup.go
// A WaitGroup waits for a collection of goroutines to finish.
// The main goroutine calls Add to set the number of
// goroutines to wait for. Then each of the goroutines
// runs and calls Done when finished. At the same time,
// Wait can be used to block until all goroutines have finished.
//
// A WaitGroup must not be copied after first use.
//
// In the terminology of the Go memory model, a call to Done
// “synchronizes before” the return of any Wait call that it unblocks.
// WaitGroup 用于等待一组 Goroutine 执行完毕。
// 主 Goroutine 调用 Add 来设置需要等待的 Goroutine 的数量
// 然后每个 Goroutine 运行并调用 Done 来确认已经执行网完毕
// 同时，Wait 可以用于阻塞并等待所有 Goroutine 完成。
//
// WaitGroup 在第一次使用后不能被复制
type WaitGroup struct {
    noCopy noCopy

    // 高32位为计数器，低32为等待者计数器
    state atomic.Uint64 // high 32 bits are counter, low 32 bits are waiter count.
    sema  uint32 // 信号量
}
```

Add/Done

在初始阶段，等待器为0，计数器随着Add正数的调用而增加

<span style='color:red'>如果Add使用错误导致计数器为负，则会立即产生panic。</span>

由于并发的效果，计数器和等待器的值是分开操作的，因此可能出现计数器已经为0，但等待器为正的情况，依次调用信号量释放产生的阻塞。

```go
// Add adds delta, which may be negative, to the WaitGroup counter.
// If the counter becomes zero, all goroutines blocked on Wait are released.
// If the counter goes negative, Add panics.
//
// Note that calls with a positive delta that occur when the counter is zero
// must happen before a Wait. Calls with a negative delta, or calls with a
// positive delta that start when the counter is greater than zero, may happen
// at any time.
// Typically this means the calls to Add should execute before the statement
// creating the goroutine or other event to be waited for.
// If a WaitGroup is reused to wait for several independent sets of events,
// new Add calls must happen after all previous Wait calls have returned.
// See the WaitGroup example.
// Add 将 delta（可能为负）加到 WaitGroup 的计数器上
// 如果计数器归零，则所有阻塞在 Wait 的 Goroutine 被释放
// 如果计数器为负，则 panic
//
// 请注意，当计数器为 0 时发生的带有正的 delta 的调用必须在 Wait 之前。
// 当计数器大于 0 时，带有负 delta 的调用或带有正 delta 调用可能在任何时候发生。
// 通常，这意味着 Add 调用必须发生在 Goroutine 创建之前或其他被等待事件之前。
// 如果一个 WaitGroup 被复用于等待几个不同的独立事件集合，必须在前一个 Wait 调用返回后才能调用 Add。
func (wg *WaitGroup) Add(delta int) {
    if race.Enabled {
        if delta < 0 {
            // Synchronize decrements with Wait.
            race.ReleaseMerge(unsafe.Pointer(wg))
        }
        race.Disable()
        defer race.Enable()
    }
    // 计数器追加
    state := wg.state.Add(uint64(delta) << 32)
    // 计数器的值
    v := int32(state >> 32)
    // 等待器的值
    w := uint32(state)
    if race.Enabled && delta > 0 && v == int32(delta) {
        // The first increment must be synchronized with Wait.
        // Need to model this as a read, because there can be
        // several concurrent wg.counter transitions from 0.
        race.Read(unsafe.Pointer(&wg.sema))
    }
    // 如果实际计数器为负，则直接Panic
    if v < 0 {
        panic("sync: negative WaitGroup counter")
    }
    // 在已经调用 Wait 开始等待时，仍然使用 Add 增加计数。这样会导致 WaitGroup 的计数不准确，从而可能导致 goroutine 永远无法退出等待状态，或者其他非预期的行为。
    if w != 0 && delta > 0 && v == int32(delta) {
        panic("sync: WaitGroup misuse: Add called concurrently with Wait")
    }
    // 正常情况直接返回
    if v > 0 || w == 0 {
        return
    }
    // This goroutine has set counter to 0 when waiters > 0.
    // Now there can't be concurrent mutations of state:
    // - Adds must not happen concurrently with Wait,
    // - Wait does not increment waiters if it sees counter == 0.
    // Still do a cheap sanity check to detect WaitGroup misuse.
    // v == 0 w != 0
    // 处理等待的协程
    if wg.state.Load() != state {
        panic("sync: WaitGroup misuse: Add called concurrently with Wait")
    }
    // Reset waiters count to 0.
    wg.state.Store(0)
    // 唤醒所有等待的协程
    for ; w != 0; w-- {
        runtime_Semrelease(&wg.sema, false, 0)
    }
}

// Done decrements the WaitGroup counter by one.
func (wg *WaitGroup) Done() {
    wg.Add(-1)
}
```

Wait

当Add和Done都被合理的设置后，我们希望等待所有的协程结束，此时需要调用Wait。

Wait使用的是一个简单的死循环来进行操作。在循环体中，每次先读取计数器和等待器的值。然后等待计数，如果增加成功，会阻塞当前的死循环，直到被释放才继续执行。

```go
// Wait blocks until the WaitGroup counter is zero.
func (wg *WaitGroup) Wait() {
    if race.Enabled {
        race.Disable()
    }
    for {
        // 加载当前状态
        state := wg.state.Load()
        // 计数器数量
        v := int32(state >> 32)
        // 等待器数量
        w := uint32(state)
        // 计数器为0，说明所有的协程都已经完成，当前的Wait调用可以直接返回
        if v == 0 {
            // Counter is 0, no need to wait.
            if race.Enabled {
                race.Enable()
                race.Acquire(unsafe.Pointer(wg))
            }
            return
        }
        // Increment waiters count.
        // 增加等待者计数
        if wg.state.CompareAndSwap(state, state+1) {
            if race.Enabled && w == 0 {
                // Wait must be synchronized with the first Add.
                // Need to model this is as a write to race with the read in Add.
                // As a consequence, can do the write only for the first waiter,
                // otherwise concurrent Waits will race with each other.
                race.Write(unsafe.Pointer(&wg.sema))
            }
            // 阻塞等待
            runtime_Semacquire(&wg.sema)
            // 如果计数器在Wait返回之前没有恢复到0，则panic
            // WaitGroup被误用导致Wait没有返回之前再次使用Add
            if wg.state.Load() != 0 {
                panic("sync: WaitGroup is reused before previous Wait has returned")
            }
            if race.Enabled {
                race.Enable()
                race.Acquire(unsafe.Pointer(wg))
            }
            return
        }
    }
}
```

示例：

```go
wg := sync.WaitGroup{}
wg.Add(1)
go func() { wg.Done() }()
wg.Wait()
```

在 wg 创建之初，计数器、等待器、存储原语的值均初始化为零值。不妨假设调用 `wg.Add(1)`，则计数器加 1 等待器、存储原语保持不变，均为 0。

`wg.Done()` 和 `wg.Wait()` 的调用顺序可能成两种情况：

**情况 1**：先调用 `wg.Done()` 再调用 `wg.Wait()`。

这时候 `wg.Done()` 使计数器减 1 ，这时计数器、等待器、存储原语均为 0，由于等待器为 0 则 `runtime_Semrelease` 不会被调用。 于是当 `wg.Wait()` 开始调用时，读取到计数器已经为 0，循环退出，`wg.Wait()` 调用完毕。

**情况 2**：先调用 `wg.Wait()` 再调用 `wg.Done()`。

这时候 `wg.Wait()` 开始调用时，读取到计数器为 1，则为等待器加 1，并调用 `runtime_Semacquire` 开始阻塞在存储原语为 0 的状态。

在阻塞的过程中，Goroutine 被调度器调度，开始执行 `wg.Done()`，于是计数器清零，但由于等待器为 1 大于零。 这时将等待器也清零，并调用与等待器技术相同次数（此处为 1 次）的 `runtime_Semrelease`，这导致存储原语的值变为 1，计数器和等待器均为零。 这时，`runtime_Semacquire` 在存储原语大于零后被唤醒，这时检查计数器和等待器是否为零（如果不为零则说明 Add 与 Wait 产生并发调用，直接 panic），这时他们为 0，结束阻塞。

## 5、缓存池

sync.Pool是一个临时对象池，管理一组临时对象，当需要从池中获取，使用完毕后再放回池中，以供他人使用。

### 底层结构

内部本质上保存了一个pool Local元素的数组，每个poolLocal都只能被一个P拥有，而victim则缓存上一个垃圾回收周期的local。

```go
// src/sync/pool.go
// A Pool is a set of temporary objects that may be individually saved and
// retrieved.
//
// Any item stored in the Pool may be removed automatically at any time without
// notification. If the Pool holds the only reference when this happens, the
// item might be deallocated.
//
// A Pool is safe for use by multiple goroutines simultaneously.
//
// Pool's purpose is to cache allocated but unused items for later reuse,
// relieving pressure on the garbage collector. That is, it makes it easy to
// build efficient, thread-safe free lists. However, it is not suitable for all
// free lists.
//
// An appropriate use of a Pool is to manage a group of temporary items
// silently shared among and potentially reused by concurrent independent
// clients of a package. Pool provides a way to amortize allocation overhead
// across many clients.
//
// An example of good use of a Pool is in the fmt package, which maintains a
// dynamically-sized store of temporary output buffers. The store scales under
// load (when many goroutines are actively printing) and shrinks when
// quiescent.
//
// On the other hand, a free list maintained as part of a short-lived object is
// not a suitable use for a Pool, since the overhead does not amortize well in
// that scenario. It is more efficient to have such objects implement their own
// free list.
//
// A Pool must not be copied after first use.
//
// In the terminology of the Go memory model, a call to Put(x) “synchronizes before”
// a call to Get returning that same value x.
// Similarly, a call to New returning x “synchronizes before”
// a call to Get returning that same value x.
type Pool struct {
    noCopy noCopy

    // local 固定大小 per-P 数组, 实际类型为 [P]poolLocal
    local     unsafe.Pointer // local fixed-size per-P pool, actual type is [P]poolLocal
    localSize uintptr        // size of the local array local array 的大小

    // 来自前一个垃圾回收周期的 local
    victim     unsafe.Pointer // local from previous cycle
    victimSize uintptr        // size of victims array victim 数组的大小

    // New optionally specifies a function to generate
    // a value when Get would otherwise return nil.
    // It may not be changed concurrently with calls to Get.
    New func() any
}
```

而poolLocal则由private和shared两个字段组成，private是上次访问放入的对象，shared是一个链式队列结构，可以在多个P之间进行共享读写。

```go

// Local per-P Pool appendix.
type poolLocalInternal struct {
    // 只能被一个P读写
    // private用于快速访问上次放入的对象
    private any // Can be used only by the respective P.
    // 可以在多个P之间共享读写
    shared poolChain // Local P can pushHead/popHead; any P can popTail.
}

// 每个poolLocal都只被一个P拥有
type poolLocal struct {
    poolLocalInternal

    // Prevents false sharing on widespread platforms with
    // 128 mod (cache line size) = 0 .
    pad [128 - unsafe.Sizeof(poolLocalInternal{})%128]byte
}
```

### Get

从池中获取对象时，会先从poolLocal的数组中选一个poolLocal

1、优先从private取出上次回收的对象

2、如果取不到，则尝试从shared队列的队头进行读取

3、还是取不到则从其他P的poolLocal中偷取

4、最后还没有取到，则使用New方法新建

```go
// Get selects an arbitrary item from the Pool, removes it from the
// Pool, and returns it to the caller.
// Get may choose to ignore the pool and treat it as empty.
// Callers should not assume any relation between values passed to Put and
// the values returned by Get.
//
// If Get would otherwise return nil and p.New is non-nil, Get returns
// the result of calling p.New.
// Get 从 Pool 中选择一个任意的对象，将其移出 Pool, 并返回给调用方。
// Get 可能会返回一个非零值对象（被其他人使用过），因此调用方不应假设
// 返回的对象具有任何形式的状态。
func (p *Pool) Get() any {
    if race.Enabled {
        race.Disable()
    }
    // 获取一个poolLocal
    l, pid := p.pin()
    // 先从private获取上次访问放入的对象
    x := l.private
    l.private = nil
    if x == nil {
        // Try to pop the head of the local shard. We prefer
        // the head over the tail for temporal locality of
        // reuse.
        // 尝试从shared队列获取对象
        x, _ = l.shared.popHead()
        if x == nil {
            // shared中也没有，则从其他poolLocal或者全局池中获取
            x = p.getSlow(pid)
        }
    }
    runtime_procUnpin()
    if race.Enabled {
        race.Enable()
        if x != nil {
            race.Acquire(poolRaceAddr(x))
        }
    }
    if x == nil && p.New != nil {
        // 池中没有则直接创建
        x = p.New()
    }
    return x
}
```

注意：

1. private只保存了一个对象，就是最近回收的。
2. 第一次从shared中取对象时，未涉及跨P读写，因此popHead可用
3. 当shared读取不到对象时，说明当前局部P所持有的poolLocal不包含任何对象，需要从其他P的poolLocal中偷取。
4. 实在偷不到会新建一个对象。

偷取细节

1、首先需要获取当前P的poolLocal，并将当前协程绑定到该P上。这主要通过pin（）函数来完成。

它首先会调用运行时实现获得当前P的id，将P设置为禁止抢占，达到固定当前协程的目的。然后检查pid和localSize来确保从local取值不会发生越界。不发生则调用相应函数取值。否则调用慢速路径获取。

`pinSlow()` 会首先取消 P 的禁止抢占，这是因为使用 mutex 时 P 必须为可抢占的状态。 然后使用 `allPoolsMu` 进行加锁。 当完成加锁后，再重新固定 P ，取其 pid。注意，因为中途可能已经被其他的线程调用，因此这时候需要再次对 pid 进行检查。 如果 pid 在 p.local 大小范围内，则不再此时创建，直接返回。

如果 `p.local` 为空，则将 p 扔给 `allPools` 并在垃圾回收阶段回收所有 Pool 实例。 最后再完成对 `p.local` 的创建（彻底丢弃旧数组）

```go
// pin pins the current goroutine to P, disables preemption and
// returns poolLocal pool for the P and the P's id.
// Caller must call runtime_procUnpin() when done with the pool.
// 将当前的 goroutine 固定在特定的 P（处理器）上，并返回与该 P 关联的 poolLocal 对象和 P 的 ID。
func (p *Pool) pin() (*poolLocal, int) {
    // 绑定当前P，保证后续的操作都在同一个P上执行
    pid := runtime_procPin()
    // In pinSlow we store to local and then to localSize, here we load in opposite order.
    // Since we've disabled preemption, GC cannot happen in between.
    // Thus here we must observe local at least as large localSize.
    // We can observe a newer/larger local, it is fine (we must observe its zero-initialized-ness).
    // 读取localSize，再读取local
    // 读取的顺序很重要，先读取localSize，再读取local，local至少是被正确初始化的
    s := runtime_LoadAcquintptr(&p.localSize) // load-acquire 确保读取的值在读取之前所有的写操作都已经完成了
    l := p.local                              // load-consume
    if uintptr(pid) < s {
        // 如果pid在local数组中，直接找到并使用
        return indexLocal(l, pid), pid
    }
    // 尝试扩展local数组
    return p.pinSlow()
}

func (p *Pool) pinSlow() (*poolLocal, int) {
    // Retry under the mutex.
    // Can not lock the mutex while pinned.
    // 获取全局锁，需要解除绑定状态
    runtime_procUnpin()
    allPoolsMu.Lock()
    defer allPoolsMu.Unlock()
    // 重新固定
    pid := runtime_procPin()
    // poolCleanup won't be called while we are pinned.
    // 检查local是否已经重新分配
    s := p.localSize
    l := p.local
    if uintptr(pid) < s {
        return indexLocal(l, pid), pid
    }
    // 将其添加到 allPools，垃圾回收器从这里获取所有 Pool 实例
    if p.local == nil {
        allPools = append(allPools, p)
    }
    // If GOMAXPROCS changes between GCs, we re-allocate the array and lose the old one.
    // 根据 P 数量创建 slice，如果 GOMAXPROCS 在 GC 间发生变化
    // 我们重新分配此数组并丢弃旧的
    size := runtime.GOMAXPROCS(0)
    local := make([]poolLocal, size)
    // 将底层数组起始指针保存到 p.local，并设置 p.localSize
    atomic.StorePointer(&p.local, unsafe.Pointer(&local[0])) // store-release
    runtime_StoreReluintptr(&p.localSize, uintptr(size))     // store-release
    return &local[pid], pid
}

func indexLocal(l unsafe.Pointer, i int) *poolLocal {
    lp := unsafe.Pointer(uintptr(l) + uintptr(i)*unsafe.Sizeof(poolLocal{}))
    return (*poolLocal)(lp)
}

```

2、getSlow

获取到了 `poolLocal`，现在回到我们 `Get` 的取值过程。在取对象的过程中，我们仍然会面临 既不能从 `private` 取、也不能从 `shared` 中取得尴尬境地。这时候就来到了 `getSlow()`。

再次固定 P，并取得当前的 P.id 来从其他 P 中偷值，那么我们需要先获取到其他 P 对应的 `poolLocal`

```go
func (p *Pool) getSlow(pid int) any {
    // See the comment in pin regarding ordering of the loads.
    size := runtime_LoadAcquintptr(&p.localSize) // load-acquire
    locals := p.local                            // load-consume
    // Try to steal one element from other procs.
    for i := 0; i < int(size); i++ {
        // 获取目标 poolLocal, 引入 pid 保证不是自身
        l := indexLocal(locals, (pid+i+1)%int(size))
        // 从其他的 P 中固定的 localPool 的 share 队列的队尾偷一个缓存对象
        if x, _ := l.shared.popTail(); x != nil {
            return x
        }
    }

    // Try the victim cache. We do this after attempting to steal
    // from all primary caches because we want objects in the
    // victim cache to age out if at all possible.
    // 当 local 失败后，尝试再尝试从上一个垃圾回收周期遗留下来的 victim。
    // 如果 pid 比 victim 遗留的 localPool 还大，则说明从根据此 pid 从
    // victim 获取 localPool 会发生越界（同时也表明此时 P 的数量已经发生变化）
    // 这时无法继续读取，直接返回 nil
    size = atomic.LoadUintptr(&p.victimSize)
    if uintptr(pid) >= size {
        return nil
    }
    // 获取 localPool，并优先读取 private
    locals = p.victim
    l := indexLocal(locals, pid)
    if x := l.private; x != nil {
        l.private = nil
        return x
    }
    for i := 0; i < int(size); i++ {
        // 从其他的 P 中固定的 localPool 的 share 队列的队尾偷一个缓存对象
        l := indexLocal(locals, (pid+i)%int(size))
        if x, _ := l.shared.popTail(); x != nil {
            return x
        }
    }

    // Mark the victim cache as empty for future gets don't bother
    // with it.
    // 将 victim 缓存置空，从而确保之后的 get 操作不再读取此处的值
    atomic.StoreUintptr(&p.victimSize, 0)

    return nil
}
```

### Put

Put只需要将对象放回到池中

1、优先放入private

2、private有值，则放入shared。

```go
// Put adds x to the pool.
func (p *Pool) Put(x any) {
    if x == nil {
        return
    }
    if race.Enabled {
        if fastrandn(4) == 0 {
            // Randomly drop x on floor.
            return
        }
        race.ReleaseMerge(poolRaceAddr(x))
        race.Disable()
    }
    // 获取一个poolLocal
    l, _ := p.pin()
    // 优先放入private
    if l.private == nil {
        l.private = x
    } else {
        // 不能则放入shared头部
        l.shared.pushHead(x)
    }
    runtime_procUnpin()
    if race.Enabled {
        race.Enable()
    }
}
```

### 缓存回收

`sync.Pool` 的垃圾回收发生在运行时 GC 开始之前。

```go
func init() {
    // pool的垃圾回收发生在运行时GC开始之前
    // 将缓存清理函数注册到运行时 GC 时间段
    runtime_registerPoolCleanup(poolCleanup)
}
```

即便是最后 `p.local` 已经被置换到 `oldPools` 的 `p.victim`，其中的缓存对象仍然有可能被偷取放回到 `allPools` 中，从而延缓了 `victim` 中缓存对象被回收的速度。

```go
// oldPools 是一组 pool 的集合，具有非空 victim 缓存。由 STW 保护
var oldPools []*Pool

func poolCleanup() {
    // This function is called with the world stopped, at the beginning of a garbage collection.
    // It must not allocate and probably should not call any runtime functions.

    // Because the world is stopped, no pool user can be in a
    // pinned section (in effect, this has all Ps pinned).
    // 程序此时已经暂停，无需加锁

    // Drop victim caches from all pools.
    // 从所有的oldpools中删除victim
    for _, p := range oldPools {
        p.victim = nil
        p.victimSize = 0
    }

    // Move primary cache to victim cache.
    // 将主缓存移动到 victim 缓存
    for _, p := range allPools {
        p.victim = p.local
        p.victimSize = p.localSize
        p.local = nil
        p.localSize = 0
    }

    // The pools with non-empty primary caches now have non-empty
    // victim caches and no pools have primary caches.
    // 具有非空主缓存的池现在具有非空的 victim 缓存，并且没有任何 pool 具有主缓存。
    oldPools, allPools = allPools, nil
}
```

### poolChain

内部结构

```go
// src/sync/poolDequeue.go
// poolChain is a dynamically-sized version of poolDequeue.
//
// This is implemented as a doubly-linked list queue of poolDequeues
// where each dequeue is double the size of the previous one. Once a
// dequeue fills up, this allocates a new one and only ever pushes to
// the latest dequeue. Pops happen from the other end of the list and
// once a dequeue is exhausted, it gets removed from the list.
// 一个双向链式队列，每个元素都是一个环形队列
type poolChain struct {
    // head is the poolDequeue to push to. This is only accessed
    // by the producer, so doesn't need to be synchronized.
    // 仅由生产者访问，无需并发安全
    // 指向最近插入的节点，并不是传统意义上的链表头部
    head *poolChainElt

    // tail is the poolDequeue to popTail from. This is accessed
    // by consumers, so reads and writes must be atomic.
    // 由多个消费者访问，需要保证并发安全
    tail *poolChainElt
}

type poolChainElt struct {
    poolDequeue

    // next and prev link to the adjacent poolChainElts in this
    // poolChain.
    //
    // next is written atomically by the producer and read
    // atomically by the consumer. It only transitions from nil to
    // non-nil.
    //
    // prev is written atomically by the consumer and read
    // atomically by the producer. It only transitions from
    // non-nil to nil.
    next, prev *poolChainElt
}
```

`poolChain` 实际上是多个生产者消费者模型的链表。 对于一个局部 P 而言，充当了多个队头的单一生产者，它可以安全的 在整个链表中所串联的队列的队头进行操作。 而其他的多个 P 而言，则充当了多个队尾的消费者， 可以在所串联的队列的队尾进行消费（偷取）。

`popHead` 操作发生在从本地 shared 队列中消费并获取对象（消费者）。 `pushHead` 操作发生在向本地 shared 队列中放置对象（生产者）。 `popTail` 操作则发生在从其他 P 的 shared 队列中偷取的过程。

```go
func (c *poolChain) pushHead(val any) {
    d := c.head
    // 链表为空，初始化一个链表
    if d == nil {
        // Initialize the chain.
        const initSize = 8 // Must be a power of 2
        d = new(poolChainElt)
        d.vals = make([]eface, initSize)
        c.head = d
        storePoolChainElt(&c.tail, d)
    }

    // 向队列中存值成功，则返回
    if d.pushHead(val) {
        return
    }

    // The current dequeue is full. Allocate a new one of twice
    // the size.
    // 队列已满，则分配一个原来两倍大小的队列
    newSize := len(d.vals) * 2
    if newSize >= dequeueLimit {
        // Can't make it any bigger.
        // 最大上限值
        newSize = dequeueLimit
    }

    d2 := &poolChainElt{prev: d}
    d2.vals = make([]eface, newSize)
    c.head = d2
    storePoolChainElt(&d.next, d2)
    d2.pushHead(val)
}

func (c *poolChain) popHead() (any, bool) {
    d := c.head
    // 遍历链表
    for d != nil {
        if val, ok := d.popHead(); ok {
            return val, ok
        }
        // There may still be unconsumed elements in the
        // previous dequeue, so try backing up.
        // 前一个节点可能仍然有未消耗完的元素
        d = loadPoolChainElt(&d.prev)
    }
    return nil, false
}

func (c *poolChain) popTail() (any, bool) {
    d := loadPoolChainElt(&c.tail)
    if d == nil {
        return nil, false
    }

    for {
        // It's important that we load the next pointer
        // *before* popping the tail. In general, d may be
        // transiently empty, but if next is non-nil before
        // the pop and the pop fails, then d is permanently
        // empty, which is the only condition under which it's
        // safe to drop d from the chain.
        d2 := loadPoolChainElt(&d.next)

        if val, ok := d.popTail(); ok {
            return val, ok
        }

        if d2 == nil {
            // This is the only dequeue. It's empty right
            // now, but could be pushed to in the future.
            return nil, false
        }

        // The tail of the chain has been drained, so move on
        // to the next dequeue. Try to drop it from the chain
        // so the next pop doesn't have to look at the empty
        // dequeue again.
        // CAS操作，更新tail指针
        if atomic.CompareAndSwapPointer((*unsafe.Pointer)(unsafe.Pointer(&c.tail)), unsafe.Pointer(d), unsafe.Pointer(d2)) {
            // We won the race. Clear the prev pointer so
            // the garbage collector can collect the empty
            // dequeue and so popHead doesn't back up
            // further than necessary.
            storePoolChainElt(&d2.prev, nil)
        }
        d = d2
    }
}
```

### poolDequeue

内部结构

```go
// poolDequeue is a lock-free fixed-size single-producer,
// multi-consumer queue. The single producer can both push and pop
// from the head, and consumers can pop from the tail.
//
// It has the added feature that it nils out unused slots to avoid
// unnecessary retention of objects. This is important for sync.Pool,
// but not typically a property considered in the literature.
// 一个单生产者、多消费者的固定长度的环形队列
type poolDequeue struct {
    // headTail packs together a 32-bit head index and a 32-bit
    // tail index. Both are indexes into vals modulo len(vals)-1.
    //
    // tail = index of oldest data in queue
    // head = index of next slot to fill
    //
    // Slots in the range [tail, head) are owned by consumers.
    // A consumer continues to own a slot outside this range until
    // it nils the slot, at which point ownership passes to the
    // producer.
    //
    // The head index is stored in the most-significant bits so
    // that we can atomically add to it and the overflow is
    // harmless.
    // 前32位表示下一个需要被填充的对象槽的索引
    // 后32位表示了队列中最先被插入的数据的索引
    headTail uint64

    // vals is a ring buffer of interface{} values stored in this
    // dequeue. The size of this must be a power of 2.
    //
    // vals[i].typ is nil if the slot is empty and non-nil
    // otherwise. A slot is still in use until *both* the tail
    // index has moved beyond it and typ has been set to nil. This
    // is set to nil atomically by the consumer and read
    // atomically by the producer.
    // 存储实际的对象
    vals []eface
}

type eface struct {
    typ, val unsafe.Pointer
}
```

`poolDequeue` 是一个单生产者、多消费者的固定长度的环状队列， `popHead`、`pushHead` 由局部的 P 操作队首，而 `popTail` 由其他并行的 P 操作队尾。 其中 `headTail` 字段的前 32 位表示了下一个需要被填充的对象槽的索引， 而后 32 位则表示了队列中最先被插入的数据的索引。

通过 `pack`/`unpack`方法来实现对`head`和`tail` 的读写

```go
// 将 head 和 tail 指针从 d.headTail 中分离开来
func (d *poolDequeue) unpack(ptrs uint64) (head, tail uint32) {
    const mask = 1<<dequeueBits - 1
    head = uint32((ptrs >> dequeueBits) & mask)
    tail = uint32(ptrs & mask)
    return
}

// 将 head 和 tail 指针打包到 d.headTail 一个 64bit 的变量中
func (d *poolDequeue) pack(head, tail uint32) uint64 {
    const mask = 1<<dequeueBits - 1
    return (uint64(head) << dequeueBits) |
        uint64(tail&mask)
}
```

从 `poolChain` 的实现中我们可以看到，每个 `poolDequeue` 的 `vals` 长度为 8。 但由于是循环队列，实现中并不关心队列的长度，只要收尾元素的索引相等，则说明队列已满。 因此通过 CAS 原语实现单一生产者的对队头的读 `popHead` 和写 `pushHead`

通过 `interface{}` 的 typ 和 val 两段式 结构的读写先后顺序，在 `popTail` 和 `pushHead` 之间消除了竞争

```go
// pushHead adds val at the head of the queue. It returns false if the
// queue is full. It must only be called by a single producer.
func (d *poolDequeue) pushHead(val any) bool {
    ptrs := atomic.LoadUint64(&d.headTail)
    head, tail := d.unpack(ptrs)
    if (tail+uint32(len(d.vals)))&(1<<dequeueBits-1) == head {
        // Queue is full.
        // 队列满了
        return false
    }
    slot := &d.vals[head&uint32(len(d.vals)-1)]

    // Check if the head slot has been released by popTail.
    // 此处可能和popTail发生竞争
    typ := atomic.LoadPointer(&slot.typ)
    if typ != nil {
        // Another goroutine is still cleaning up the tail, so
        // the queue is actually still full.
        // 其他协程在调用popTail清理，此时队列仍然是满的
        return false
    }

    // The head slot is free, so we own it.
    if val == nil {
        val = dequeueNil(nil)
    }
    *(*any)(unsafe.Pointer(slot)) = val

    // Increment head. This passes ownership of slot to popTail
    // and acts as a store barrier for writing the slot.
    atomic.AddUint64(&d.headTail, 1<<dequeueBits)
    return true
}

// popHead removes and returns the element at the head of the queue.
// It returns false if the queue is empty. It must only be called by a
// single producer.
func (d *poolDequeue) popHead() (any, bool) {
    var slot *eface
    for {
        ptrs := atomic.LoadUint64(&d.headTail)
        head, tail := d.unpack(ptrs)
        // 队列满了
        if tail == head {
            // Queue is empty.
            return nil, false
        }

        // Confirm tail and decrement head. We do this before
        // reading the value to take back ownership of this
        // slot.
        head--
        ptrs2 := d.pack(head, tail)
        if atomic.CompareAndSwapUint64(&d.headTail, ptrs, ptrs2) {
            // We successfully took back slot.
            slot = &d.vals[head&uint32(len(d.vals)-1)]
            break
        }
    }

    val := *(*any)(unsafe.Pointer(slot))
    if val == dequeueNil(nil) {
        val = nil
    }
    // Zero the slot. Unlike popTail, this isn't racing with
    // pushHead, so we don't need to be careful here.
    *slot = eface{}
    return val, true
}

// popTail removes and returns the element at the tail of the queue.
// It returns false if the queue is empty. It may be called by any
// number of consumers.
func (d *poolDequeue) popTail() (any, bool) {
    var slot *eface
    for {
        ptrs := atomic.LoadUint64(&d.headTail)
        head, tail := d.unpack(ptrs)
        if tail == head {
            // Queue is empty.
            return nil, false
        }

        // Confirm head and tail (for our speculative check
        // above) and increment tail. If this succeeds, then
        // we own the slot at tail.
        ptrs2 := d.pack(head, tail+1)
        if atomic.CompareAndSwapUint64(&d.headTail, ptrs, ptrs2) {
            // Success.
            slot = &d.vals[tail&uint32(len(d.vals)-1)]
            break
        }
    }

    // We now own slot.
    val := *(*any)(unsafe.Pointer(slot))
    if val == dequeueNil(nil) {
        val = nil
    }

    // Tell pushHead that we're done with this slot. Zeroing the
    // slot is also important so we don't leave behind references
    // that could keep this object live longer than necessary.
    //
    // We write to val first and then publish that we're done with
    // this slot by atomically writing to typ.
    // 注意：此处可能与 pushHead 发生竞争，解决方案是：
    // 1. 让 pushHead 先读取 typ 的值，如果 typ 值不为 nil，则说明 popTail 尚未清理完 slot
    // 2. 让 popTail 先清理掉 val 中的内容，在清理掉 typ，从而确保不会与 pushHead 对 slot 的写行为发生竞争
    slot.val = nil
    atomic.StorePointer(&slot.typ, nil)
    // At this point pushHead owns the slot.

    return val, true
}
```

一个 goroutine 固定在 P 上，从当前 P 对应的 `private` 取值， shared 字段作为一个优化过的链式无锁变长队列，当在 `private` 取不到值的情况下， 从对应的 `shared` 队列的队首取，若还是取不到，则尝试从其他 P 的 `shared` 队列队尾中偷取。 若偷不到，则尝试从上一个 GC 周期遗留到 `victim` 缓存中取，否则调用 `New` 创建一个新的对象。

对于回收而言，池中所有临时对象在一次 GC 后会被放入 `victim` 缓存中， 而前一个周期被放入 `victim` 的缓存则会被清理掉。

对于调用方而言，当 Get 到临时对象后，便脱离了池本身不受控制。 用方有责任将使用完的对象放回池中。

这种两级缓存的优化的优势在于：

1. 显著降低了 GC 发生前清理当前周期中产生的大量缓存对象的影响：因为回收被推迟到了下个 GC 周期；
2. 显著降低了 GC 发生后 New 对象的成本：因为密集的缓存对象读写可能从上个周期中未清理的对象中偷取。

## 6、sync.Map

<span style='color:red'>语言内建的散列表map结构并不是并发安全的，在并发的对该结构进行读写的时候，甚至可能产生不可恢复的运行时恐慌，导致程序将不受控制的崩溃。为了解决并发问题，sync包提供了一种特殊的并发安全的散列表Map结构。该结构的实现主要针对了读多写少的这一特殊场景进行的优化。</span>

### 结构

在这个结构中，可以看到read和dirty分别对应两个map，但read采用原子化的指针类型。

<span style='color:red'>sync.Map 的思路是发生足够多的读时，就将 dirty map 复制一份到 read map 上。 从而实现在 read map 上的读操作不再需要昂贵的 Mutex 操作。</span>

```go
// src/sync/map.go
// Map is like a Go map[interface{}]interface{} but is safe for concurrent use
// by multiple goroutines without additional locking or coordination.
// Loads, stores, and deletes run in amortized constant time.
//
// The Map type is specialized. Most code should use a plain Go map instead,
// with separate locking or coordination, for better type safety and to make it
// easier to maintain other invariants along with the map content.
//
// The Map type is optimized for two common use cases: (1) when the entry for a given
// key is only ever written once but read many times, as in caches that only grow,
// or (2) when multiple goroutines read, write, and overwrite entries for disjoint
// sets of keys. In these two cases, use of a Map may significantly reduce lock
// contention compared to a Go map paired with a separate Mutex or RWMutex.
//
// The zero Map is empty and ready for use. A Map must not be copied after first use.
//
// In the terminology of the Go memory model, Map arranges that a write operation
// “synchronizes before” any read operation that observes the effect of the write, where
// read and write operations are defined as follows.
// Load, LoadAndDelete, LoadOrStore, Swap, CompareAndSwap, and CompareAndDelete
// are read operations; Delete, LoadAndDelete, Store, and Swap are write operations;
// LoadOrStore is a write operation when it returns loaded set to false;
// CompareAndSwap is a write operation when it returns swapped set to true;
// and CompareAndDelete is a write operation when it returns deleted set to true.
// Map 是一种并发安全的 map[interface{}]interface{}，在多个 goroutine 中没有额外的锁条件
// 读取、存储和删除操作的时间复杂度平均为常量
//
// Map 类型非常特殊，大部分代码应该使用原始的 Go map。它具有单独的锁或协调以获得类型安全且更易维护。
//
// Map 类型针对两种常见的用例进行优化：
// 1. 给定 key 只会产生写一次但是却会多次读，类似乎只增的缓存
// 2. 多个 goroutine 读、写以及覆盖不同的 key
// 这两种情况下，与单独使用 Mutex 或 RWMutex 的 map 相比，会显著降低竞争情况
//
// 零值 Map 为空且可以直接使用，Map 使用后不能复制
type Map struct {
    mu Mutex

    // read contains the portion of the map's contents that are safe for
    // concurrent access (with or without mu held).
    //
    // The read field itself is always safe to load, but must only be stored with
    // mu held.
    //
    // Entries stored in read may be updated concurrently without mu, but updating
    // a previously-expunged entry requires that the entry be copied to the dirty
    // map and unexpunged with mu held.
    // read 包含 map 内容的一部分，这些内容对于并发访问是安全的（有或不使用 mu）。
    //
    // read 字段 load 总是安全的，但是必须使用 mu 进行 store。
    //
    // 存储在 read 中的 entry 可以在没有 mu 的情况下并发更新，
    // 但是更新已经删除的 entry 需要将 entry 复制到 dirty map 中，并使用 mu 进行删除。
    read atomic.Pointer[readOnly]

    // dirty contains the portion of the map's contents that require mu to be
    // held. To ensure that the dirty map can be promoted to the read map quickly,
    // it also includes all of the non-expunged entries in the read map.
    //
    // Expunged entries are not stored in the dirty map. An expunged entry in the
    // clean map must be unexpunged and added to the dirty map before a new value
    // can be stored to it.
    //
    // If the dirty map is nil, the next write to the map will initialize it by
    // making a shallow copy of the clean map, omitting stale entries.
    // dirty 含了需要 mu 的 map 内容的一部分。为了确保将 dirty map 快速地转为 read map，
    // 它还包括了 read map 中所有未删除的 entry。
    //
    // 删除的 entry 不会存储在 dirty map 中。在 clean map 中，被删除的 entry 必须被删除并添加到 dirty 中，
    // 然后才能将新的值存储为它
    //
    // 如果 dirty map 为 nil，则下一次的写行为会通过 clean map 的浅拷贝进行初始化
    dirty map[any]*entry

    // misses counts the number of loads since the read map was last updated that
    // needed to lock mu to determine whether the key was present.
    //
    // Once enough misses have occurred to cover the cost of copying the dirty
    // map, the dirty map will be promoted to the read map (in the unamended
    // state) and the next store to the map will make a new dirty copy.
    // misses 计算了从 read map 上一次更新开始的 load 数，需要 lock 以确定 key 是否存在。
    //
    // 一旦发生足够的 misses 足以囊括复制 dirty map 的成本，dirty map 将被提升为 read map（处于未修改状态）
    // 并且 map 的下一次 store 将生成新的 dirty 副本。
    misses int
}

// readOnly is an immutable struct stored atomically in the Map.read field.
type readOnly struct {
    m map[any]*entry
    // 如果脏映射包含一些不在 m 中的键，则为 true。
    amended bool // true if the dirty map contains some key not in m.
}

// expunged is an arbitrary pointer that marks entries which have been deleted
// from the dirty map.
// expunged 是一个任意指针，用于标记已从脏映射中删除的条目。
var expunged = new(any)

// An entry is a slot in the map corresponding to a particular key.
// 只是简单的创建一个 entry
// entry 是一个对应于 map 中特殊 key 的 slot
type entry struct {
    // p points to the interface{} value stored for the entry.
    //
    // If p == nil, the entry has been deleted, and either m.dirty == nil or
    // m.dirty[key] is e.
    //
    // If p == expunged, the entry has been deleted, m.dirty != nil, and the entry
    // is missing from m.dirty.
    //
    // Otherwise, the entry is valid and recorded in m.read.m[key] and, if m.dirty
    // != nil, in m.dirty[key].
    //
    // An entry can be deleted by atomic replacement with nil: when m.dirty is
    // next created, it will atomically replace nil with expunged and leave
    // m.dirty[key] unset.
    //
    // An entry's associated value can be updated by atomic replacement, provided
    // p != expunged. If p == expunged, an entry's associated value can be updated
    // only after first setting m.dirty[key] = e so that lookups using the dirty
    // map find the entry.
    // p 指向 interface{} 类型的值，用于保存 entry
    //
    // 如果 p == nil，则 entry 已被删除，且 m.dirty == nil
    //
    // 如果 p == expunged, 则 entry 已经被删除，m.dirty != nil ，则 entry 不在 m.dirty 中
    //
    // 否则，entry 仍然有效，且被记录在 m.read.m[key] ，但如果 m.dirty != nil，则在 m.dirty[key] 中
    //
    // 一个 entry 可以被原子替换为 nil 来删除：当 m.dirty 下一次创建时，它会自动将 nil 替换为 expunged 且
    // 让 m.dirty[key] 成为未设置的状态。
    //
    // 与一个 entry 关联的值可以被原子替换式的更新，提供的 p != expunged。如果 p == expunged，
    // 则与 entry 关联的值只能在 m.dirty[key] = e 设置后被更新，因此会使用 dirty map 来查找 entry。
    p atomic.Pointer[any]
}

func newEntry(i any) *entry {
    e := &entry{}
    e.p.Store(&i)
    return e
}

func (m *Map) loadReadOnly() readOnly {
    if p := m.read.Load(); p != nil {
        return *p
    }
    return readOnly{}
}
```

### 写操作Store

首先发生的是更新已经存在值的情况： 更新操作直接更新 read map 中的值，如果成功则不需要进行任何操作，如果没有成功才继续处理。

```go
// trySwap swaps a value if the entry has not been expunged.
//
// If the entry is expunged, trySwap returns false and leaves the entry
// unchanged.
// 如果条目尚未删除，trySwap 会交换一个值。如果该条目被删除，trySwap 将返回 false 并保持该条目不变。
func (e *entry) trySwap(i *any) (*any, bool) {
    for {
        // 读取entry
        p := e.p.Load()
        // 如果entry已经删除则无法存储
        if p == expunged {
            return nil, false
        }
        // 交换p和i的值，成功则立即返回
        if e.p.CompareAndSwap(p, i) {
            return p, true
        }
    }
}
```

Read map可能已经更新并且存在key情况下，本质上还分两种情况：

1. 可能因为是一个已经删除的值（之前的 `tryStore` 失败）
2. 可能先前仅保存在 dirty map 然后同步到了 read map（这是可能的，我们后面读 Load 时再来分析 dirty map 是如何同步到 read map 的）

对于第一种而言，我们需要重新将这个已经删除的值标记为没有删除，然后将这个值同步回 dirty map（删除操作只删除 dirty map，之后再说） 对于第二种状态，我们直接更新 read map，不需要打扰 dirty map。

看一下 dirty map 有没有，结果发现是有的， 那么我们直接修改 dirty map，不去打扰 read map。

read map 和 dirty map 都没有，只能是存储一个新值了。当然，在更新之前 我们还要再检查一下 read map 和 dirty map 的状态。 如果 read map 和 dirty map 中存储的内容是相同的，那么我们这次存储新的数据 只会存储在 dirty map 中，因此会造成 read map 和 dirty map 的不一致。

```go
func (m *Map) dirtyLocked() {
    if m.dirty != nil {
        return
    }

    read := m.loadReadOnly()
    m.dirty = make(map[any]*entry, len(read.m))
    for k, e := range read.m {
        // 检查当前条目是否过期或失效
        if !e.tryExpungeLocked() {
            m.dirty[k] = e
        }
    }
}

func (e *entry) tryExpungeLocked() (isExpunged bool) {
    // 获取entry的值
    p := e.p.Load()
    // 如果entry的值为nil
    for p == nil {
        // 检查是否被标记为已经删除
        if e.p.CompareAndSwap(nil, expunged) {
            // 成功交换，说明已经被删除
            return true
        }
        // 删除操作失败，说明expunged等于nil，则重新读取
        p = e.p.Load()
    }
    return p == expunged
}
```



```go
// Store sets the value for a key.
func (m *Map) Store(key, value any) {
    _, _ = m.Swap(key, value)
}

// Swap swaps the value for a key and returns the previous value if any.
// The loaded result reports whether the key was present.
func (m *Map) Swap(key, value any) (previous any, loaded bool) {
    read := m.loadReadOnly()
    if e, ok := read.m[key]; ok {
        if v, ok := e.trySwap(&value); ok {
            if v == nil {
                return nil, false
            }
            return *v, true
        }
    }

    m.mu.Lock()
    // read map可能已经更新，所以重新加载一下
    read = m.loadReadOnly()
    if e, ok := read.m[key]; ok {
        // 修改一个已经存在的值
        if e.unexpungeLocked() {
            // The entry was previously expunged, which implies that there is a
            // non-nil dirty map and this entry is not in it.
            // // 说明 entry 先前是被标记为删除了的，现在我们又要存储它，只能向 dirty map 进行更新了
            m.dirty[key] = e
        }
        // 无论先前删除与否，均要更新read map
        if v := e.swapLocked(&value); v != nil {
            loaded = true
            previous = *v
        }
    } else if e, ok := m.dirty[key]; ok {
        // 更新dirty map的值
        if v := e.swapLocked(&value); v != nil {
            loaded = true
            previous = *v
        }
    } else {
        // 如果dirty map里没有read map没有的值
        if !read.amended {
            // We're adding the first new key to the dirty map.
            // Make sure it is allocated and mark the read-only map as incomplete.
            // 首次添加一个新值到dirty map中
            // 确保已被分配并标记为read map是不完备的，即dirty map有，read map没有
            m.dirtyLocked()
            // 更新amended， 标记 read map 中缺少了值（标记为两者不同）
            m.read.Store(&readOnly{m: read.m, amended: true})
        }
        // 不管 read map 和 dirty map 相同与否，正式保存新的值
        m.dirty[key] = newEntry(value)
    }
    m.mu.Unlock()
    return previous, loaded
}
```

### 读操作Load

Load 的操作就是从 dirty map 或者 read map 中查找所存储的值。

```go
// Load returns the value stored in the map for a key, or nil if no
// value is present.
// The ok result indicates whether value was found in the map.
// Load 返回了存储在 map 中对应于 key 的值 value，如果不存在则返回 nil
// ok 表示了值能否在 map 中找到
func (m *Map) Load(key any) (value any, ok bool) {
    // 获取read map
    read := m.loadReadOnly()
    // 读取对应的值
    e, ok := read.m[key]
    // 如果在 read map 中找不到，且 dirty map 包含 read map 中不存在的 key，则进一步查找
    if !ok && read.amended {
        m.mu.Lock()
        // Avoid reporting a spurious miss if m.dirty got promoted while we were
        // blocked on m.mu. (If further loads of the same key will not miss, it's
        // not worth copying the dirty map for this key.)
        // 再一次获取，双重检查
        read = m.loadReadOnly()
        e, ok = read.m[key]
        // 如果这时 read map 确实读不到，且 dirty map 与 read map 不一致
        if !ok && read.amended {
            // 从dirty map中读取
            e, ok = m.dirty[key]
            // Regardless of whether the entry was present, record a miss: this key
            // will take the slow path until the dirty map is promoted to the read
            // map.
            // 无论 entry 是否找到，记录一次 miss：该 key 会采取 slow path 进行读取，直到
            // dirty map 被提升为 read map。
            m.missLocked()
        }
        m.mu.Unlock()
    }
    // 如果 read map 或者 dirty map 中找不到 key，则确实没找到，返回 nil 和 false
    if !ok {
        return nil, false
    }
    // 找到了，返回读到的值
    return e.load()
}

func (e *entry) load() (value any, ok bool) {
    // 读entry的值
    p := e.p.Load()
    // 判断是否被删除
    if p == nil || p == expunged {
        return nil, false
    }
    // 读取值
    return *p, true
}
```

可以看到：

1. 如果 read map 中已经找到了该值，则不需要去访问 dirty map（慢）。
2. 但如果没找到，且 dirty map 与 read map 没有差异，则也不需要去访问 dirty map。
3. 如果 dirty map 和 read map 有差异，则我们需要锁住整个 Map，然后再读取一次 read map 来防止并发导致的上一次读取失误
4. 如果锁住后，确实 read map 读取不到且 dirty map 和 read map 一致，则不需要去读 dirty map 了，直接解锁返回。
5. 如果锁住后，read map 读不到，且 dirty map 与 read map 不一致，则该 key 可能在 dirty map 中，我们需要从 dirty map 中读取，并记录一次 miss（在 read map 中 miss）。

记录miss操作

miss 如果大于了 dirty 所存储的 key 数时，会将 dirty map 同步到 read map，并将自身清空，miss 计数归零。

```go
// 此方法调用时，整个 map 是锁住的
func (m *Map) missLocked() {
    // 增加miss数量
    m.misses++
    // 如果 miss 的次数小于 dirty map 的 key 数
    // 则直接返回
    if m.misses < len(m.dirty) {
        return
    }
    // 否则将 dirty map 同步到 read map 去
    m.read.Store(&readOnly{m: m.dirty})
    // 清空 dirty map
    m.dirty = nil
    // miss 计数归零
    m.misses = 0
}
```

### 删除操作Delete

删除操作相对简单，当需要删除一个值时，移除 read map 中的值，本质上仅仅只是解除对变量的引用。 实际的回收是由 GC 进行处理。 如果 read map 中并未找到要删除的值，才会去尝试删除 dirty map 中的值。

```go
// Delete deletes the value for a key.
// Delete 删除 key 对应的 value
func (m *Map) Delete(key any) {
    m.LoadAndDelete(key)
}

// LoadAndDelete deletes the value for a key, returning the previous value if any.
// The loaded result reports whether the key was present.
func (m *Map) LoadAndDelete(key any) (value any, loaded bool) {
    // 获得 read map
    read := m.loadReadOnly()
    // 从 read map 中读取需要删除的 key
    e, ok := read.m[key]
    // 如果 read map 中没找到，且 read map 与 dirty map 不一致
    // 说明要删除的值在 dirty map 中
    if !ok && read.amended {
        m.mu.Lock()
        // 再次读 read map
        read = m.loadReadOnly()
        // 从 read map 中取值
        e, ok = read.m[key]
        // 没取到，read map 和 dirty map 不一致
        if !ok && read.amended {
            e, ok = m.dirty[key]
            // 删除 dierty map 的值
            delete(m.dirty, key)
            // Regardless of whether the entry was present, record a miss: this key
            // will take the slow path until the dirty map is promoted to the read
            // map.
            // 记录一次miss
            m.missLocked()
        }
        m.mu.Unlock()
    }
    if ok {
        return e.delete()
    }
    return nil, false
}

func (e *entry) delete() (value any, ok bool) {
    for {
        // 读取 entry 的值
        p := e.p.Load()
        // 如果 p 等于 nil，或者 p 已经标记删除
        if p == nil || p == expunged {
            // 则不需要删除
            return nil, false
        }
        // 否则，将 p 的值与 nil 进行原子换
        if e.p.CompareAndSwap(p, nil) {
            // 删除成功（本质只是解除引用，实际上是留给 GC 清理）
            return *p, true
        }
    }
}
```

### 迭代操作Range

既然要 Range 整个 map，则需要考虑 dirty map 与 read map 不一致的问题，如果不一致，则直接将 dirty map 同步到 read map 中。

```go
// Range calls f sequentially for each key and value present in the map.
// If f returns false, range stops the iteration.
//
// Range does not necessarily correspond to any consistent snapshot of the Map's
// contents: no key will be visited more than once, but if the value for any key
// is stored or deleted concurrently (including by f), Range may reflect any
// mapping for that key from any point during the Range call. Range does not
// block other methods on the receiver; even f itself may call any method on m.
//
// Range may be O(N) with the number of elements in the map even if f returns
// false after a constant number of calls.
// Range 为每个 key 顺序的调用 f。如果 f 返回 false，则 range 会停止迭代。
//
// Range 的时间复杂度可能会是 O(N) 即便是 f 返回 false。
func (m *Map) Range(f func(key, value any) bool) {
    // We need to be able to iterate over all of the keys that were already
    // present at the start of the call to Range.
    // If read.amended is false, then read.m satisfies that property without
    // requiring us to hold m.mu for a long time.
    // 读取 read map
    read := m.loadReadOnly()
    // 如果 read map 和 dirty map 不一致，则需要进一步操作
    if read.amended {
        // m.dirty contains keys not in read.m. Fortunately, Range is already O(N)
        // (assuming the caller does not break out early), so a call to Range
        // amortizes an entire copy of the map: we can promote the dirty copy
        // immediately!
        m.mu.Lock()
        // 再读一次，如果还是不一致，则将 dirty map 提升为 read map
        read = m.loadReadOnly()
        if read.amended {
            read = readOnly{m: m.dirty}
            m.read.Store(&read)
            m.dirty = nil
            m.misses = 0
        }
        m.mu.Unlock()
    }

    // 在 read 变量中读（可能是 read map ，也可能是 dirty map 同步过来的 map）
    for k, e := range read.m {
        // 读 readOnly，load 会检查该值是否被标记为删除
        v, ok := e.load()
        // 如果已经删除，则跳过
        if !ok {
            continue
        }
        // 如果 f 返回 false，则停止迭代
        if !f(k, v) {
            break
        }
    }
}
```

### 读写操作LoadOrStore

`LoadOrStore` 方法无非是两则的结合

```go
// LoadOrStore returns the existing value for the key if present.
// Otherwise, it stores and returns the given value.
// The loaded result is true if the value was loaded, false if stored.
// LoadOrStore 在 key 已经存在时，返回存在的值，否则存储当前给定的值
// loaded 为 true 表示 actual 读取成功，否则为 false 表示 value 存储成功
func (m *Map) LoadOrStore(key, value any) (actual any, loaded bool) {
    // Avoid locking if it's a clean hit.
    read := m.loadReadOnly()
    // 如果 read map 中已经读到
    if e, ok := read.m[key]; ok {
        // 尝试存储（可能 key 是一个已删除的 key）
        actual, loaded, ok := e.tryLoadOrStore(value)
        // 如果存储成功，则直接返回
        if ok {
            return actual, loaded
        }
    }

    // 否则，涉及 dirty map，加锁
    m.mu.Lock()
    // 再读一次 read map
    read = m.loadReadOnly()
    if e, ok := read.m[key]; ok {
        // 如果 read map 中已经读到，则看该值是否被删除
        if e.unexpungeLocked() {
            // 没有被删除，则通过 dirty map 存
            m.dirty[key] = e
        }
        actual, loaded, _ = e.tryLoadOrStore(value)
    } else if e, ok := m.dirty[key]; ok {
        // 如果 read map 没找到, dirty map 找到了
        // 尝试 laod or store，并记录 miss
        actual, loaded, _ = e.tryLoadOrStore(value)
        m.missLocked()
    } else {
        // 否则就是存一个新的值
        // 如果 read map 和 dirty map 相同，则开始标记不同
        if !read.amended {
            // We're adding the first new key to the dirty map.
            // Make sure it is allocated and mark the read-only map as incomplete.
            m.dirtyLocked()
            m.read.Store(&readOnly{m: read.m, amended: true})
        }
        // 存到 dirty map 中去
        m.dirty[key] = newEntry(value)
        actual, loaded = value, false
    }
    m.mu.Unlock()

    return actual, loaded
}
```

sync.Map 中 read map 和 dirty map 的同步过程：

1. 当 Store 一个新值会发生：read map –> dirty map
2. dirty map –> read map：当 read map 进行 Load 失败 len(dirty map) 次之后发生

因此，无论是存储还是读取，read map 中的值一定能在 dirty map 中找到。无论两者如何同步，sync.Map 通过 entry 指针操作， 保证数据永远只有一份，一旦 read map 中的值修改，dirty map 中保存的指针就能直接读到修改后的值。

当存储新值时，一定发生在 dirty map 中。当读取旧值时，如果 read map 读到则直接返回，如果没有读到，则尝试加锁去 dirty map 中取。 这也就是官方宣称的 sync.Map 适用于一次写入多次读取的情景。
